{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Base de dados The Simpsons\n",
    "\n",
    "Baixe a base de dados com os episódios do The Simpsons no Kaggle. Utilize os códigos de referência do curso para combinar todos os arquivos CSVs num único dataset. Utilize a biblioteca tiktoken com a codificação cl100k_base para descrever a quantidade de tokens por episódios e temporada. \n",
    "\n",
    "Quantos tokens em média tem um episódio? E temporada? Qual foi a temporada e o episódio com mais tokens? Faça uma análise descritiva.\n",
    "Utilize a técnica de Prompt Chaining para fazer uma análise descritiva das avaliações do IMDB e da audiência dos episódios. Justifique os prompts gerados.\n",
    "\n",
    "Fonte Kaggle: https://www.kaggle.com/datasets/prashant111/the-simpsons-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\infnet_ultimo_semestre\\TP3_Eng_de_Prompt_Parte_2_local\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import os\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import kagglehub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\giova\\.cache\\kagglehub\\datasets\\prashant111\\the-simpsons-dataset\\versions\\1\n",
      "\n",
      "Informações do dataset combinado:\n",
      "Número total de linhas: 158271\n",
      "Número total de colunas: 30\n",
      "\n",
      "Colunas do dataset:\n",
      "['episode_id', 'number', 'raw_text', 'timestamp_in_ms', 'speaking_line', 'character_id', 'location_id', 'raw_character_text', 'raw_location_text', 'spoken_words', 'normalized_text', 'word_count', 'episode_image_url', 'episode_imdb_rating', 'episode_imdb_votes', 'episode_number_in_season', 'episode_number_in_series', 'episode_original_air_date', 'episode_original_air_year', 'episode_production_code', 'episode_season', 'episode_title', 'episode_us_viewers_in_millions', 'episode_video_url', 'episode_views', 'character_name', 'character_normalized_name', 'character_gender', 'location_name', 'location_normalized_name']\n",
      "\n",
      "DataFrame salvo com sucesso como 'simpsons_combined_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Path do dataset baixado\n",
    "path = kagglehub.dataset_download(\"prashant111/the-simpsons-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Carregar os datasets\n",
    "df_script = pd.read_csv(os.path.join(path, 'simpsons_script_lines.csv'), low_memory=False)\n",
    "df_episodes = pd.read_csv(os.path.join(path, 'simpsons_episodes.csv'), low_memory=False)\n",
    "df_characters = pd.read_csv(os.path.join(path, 'simpsons_characters.csv'), low_memory=False)\n",
    "df_locations = pd.read_csv(os.path.join(path, 'simpsons_locations.csv'), low_memory=False)\n",
    "\n",
    "# Preparar os datasets\n",
    "df_script.set_index('id', inplace=True)\n",
    "df_characters['id'] = df_characters['id'].astype(str)\n",
    "\n",
    "# Adicionar prefixos\n",
    "df_characters = df_characters.add_prefix('character_')\n",
    "df_locations = df_locations.add_prefix('location_')\n",
    "df_episodes = df_episodes.add_prefix('episode_')\n",
    "\n",
    "# Realizar merge\n",
    "data = (\n",
    "    df_script.merge(df_episodes, left_on='episode_id', right_on='episode_id')\n",
    "             .merge(df_characters, left_on='character_id', right_on='character_id', how='left')\n",
    "             .merge(df_locations, left_on='location_id', right_on='location_id', how='left')\n",
    ")\n",
    "\n",
    "# Verificar integridade\n",
    "assert data.shape[0] == df_script.shape[0]\n",
    "\n",
    "# Imprimir informações sobre o dataset combinado\n",
    "print(\"\\nInformações do dataset combinado:\")\n",
    "print(\"Número total de linhas:\", data.shape[0])\n",
    "print(\"Número total de colunas:\", data.shape[1])\n",
    "print(\"\\nColunas do dataset:\")\n",
    "print(data.columns.tolist())\n",
    "\n",
    "# Salvar o DataFrame combinado na raiz do projeto\n",
    "try:\n",
    "    data.to_csv('simpsons_combined_data.csv', index=True)\n",
    "    print(\"\\nDataFrame salvo com sucesso como 'simpsons_combined_data.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErro ao salvar o DataFrame: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análise de Tokens por Temporada:\n",
      "        mean_tokens  max_tokens  min_tokens  total_episodes\n",
      "season                                                     \n",
      "1       2814.846154        3216        2476              13\n",
      "2       2952.863636        3323        2368              22\n",
      "3       2866.208333        3422        2433              24\n",
      "4       2395.136364        2671        1622              22\n",
      "5       2649.954545        3076        1934              22\n",
      "6       2630.320000        3168        2160              25\n",
      "7       2798.760000        3156        2272              25\n",
      "8       2751.640000        3184        2326              25\n",
      "9       2569.560000        3064         861              25\n",
      "10      2730.347826        3079        2156              23\n",
      "11      2692.954545        3040        2388              22\n",
      "12      2451.476190        2809        1959              21\n",
      "13      2327.000000        2756        1243              22\n",
      "14      2583.409091        3061        2183              22\n",
      "15      2580.181818        2950        1962              22\n",
      "16      2635.095238        3032        2339              21\n",
      "17      2521.727273        2905        2207              22\n",
      "18      2337.318182        2788        1868              22\n",
      "19      2413.750000        2958        1989              20\n",
      "20      2498.736842        2800        2070              19\n",
      "21      2485.272727        2849        2053              22\n",
      "22      2458.363636        2975        1906              22\n",
      "23      2541.090909        3052        2055              22\n",
      "24      2574.681818        2880        1788              22\n",
      "25      2483.619048        3000        2164              21\n",
      "26      2346.625000        2762        1773              16\n",
      "\n",
      "Episódio com mais tokens:\n",
      "Título: Lisa the Greek\n",
      "Temporada: 3\n",
      "Tokens: 3422\n",
      "\n",
      "Estatísticas Gerais de Tokens:\n",
      "count     564.000000\n",
      "mean     2584.054965\n",
      "std       295.795664\n",
      "min       861.000000\n",
      "25%      2405.750000\n",
      "50%      2597.000000\n",
      "75%      2777.500000\n",
      "max      3422.000000\n",
      "Name: tokens, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giova\\AppData\\Local\\Temp\\ipykernel_5856\\2800432613.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  episode_tokens = data.groupby(['episode_season', 'episode_title']).apply(count_episode_tokens).reset_index()\n"
     ]
    }
   ],
   "source": [
    "# Função para contar tokens\n",
    "def count_tokens(text):\n",
    "    encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoder.encode(str(text)))\n",
    "\n",
    "# Contar tokens por episódio\n",
    "def count_episode_tokens(episode_data):\n",
    "    # Concatenar todos os textos normalizados do episódio\n",
    "    episode_text = ' '.join(episode_data['normalized_text'].dropna())\n",
    "    return count_tokens(episode_text)\n",
    "\n",
    "# Agrupar por episódio e contar tokens\n",
    "episode_tokens = data.groupby(['episode_season', 'episode_title']).apply(count_episode_tokens).reset_index()\n",
    "episode_tokens.columns = ['season', 'title', 'tokens']\n",
    "\n",
    "# Análise descritiva de tokens\n",
    "tokens_summary = episode_tokens.groupby('season')['tokens'].agg([\n",
    "    ('mean_tokens', 'mean'),\n",
    "    ('max_tokens', 'max'),\n",
    "    ('min_tokens', 'min'),\n",
    "    ('total_episodes', 'count')\n",
    "])\n",
    "\n",
    "print(\"Análise de Tokens por Temporada:\")\n",
    "print(tokens_summary)\n",
    "\n",
    "# Episódio com mais tokens\n",
    "max_tokens_episode = episode_tokens.loc[episode_tokens['tokens'].idxmax()]\n",
    "print(\"\\nEpisódio com mais tokens:\")\n",
    "print(f\"Título: {max_tokens_episode['title']}\")\n",
    "print(f\"Temporada: {max_tokens_episode['season']}\")\n",
    "print(f\"Tokens: {max_tokens_episode['tokens']}\")\n",
    "\n",
    "# Estatísticas gerais de tokens\n",
    "print(\"\\nEstatísticas Gerais de Tokens:\")\n",
    "print(episode_tokens['tokens'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pergunta 1: Quantos tokens em média tem um episódio? E temporada? Qual foi a temporada e o episódio com mais tokens? Faça uma análise descritiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Análise Descritiva dos Tokens nos Episódios de The Simpsons\n",
       "\n",
       "### Visão Geral Estatística\n",
       "- **Número Total de Episódios Analisados**: 564.0\n",
       "- **Média de Tokens por Episódio**: 2584.05 tokens\n",
       "- **Desvio Padrão**: 295.80 tokens\n",
       "\n",
       "### Distribuição de Tokens\n",
       "- **Mínimo**: 861 tokens\n",
       "- **Máximo**: 3422 tokens\n",
       "- **Mediana (50%)**: 2597.00 tokens\n",
       "\n",
       "### Interpretação Detalhada\n",
       "1. **Consistência Narrativa**\n",
       "   - A pequena variação no desvio padrão (cerca de 11.4% da média) sugere uma consistência significativa no tamanho dos diálogos entre os episódios.\n",
       "\n",
       "2. **Amplitude de Variação**\n",
       "   - Existe uma variação considerável entre o episódio mais curto (861 tokens) e o mais longo (3422 tokens), representando uma diferença de quase 4.0 vezes.\n",
       "\n",
       "3. **Distribuição Simétrica**\n",
       "   - A proximidade entre média (2584.05) e mediana (2597.00) indica uma distribuição relativamente simétrica dos tokens.\n",
       "\n",
       "4. **Quartis**\n",
       "   - 25% dos episódios têm até 2406 tokens\n",
       "   - 75% dos episódios têm até 2778 tokens\n",
       "\n",
       "### Conclusão\n",
       "Os episódios de The Simpsons mantêm uma notável consistência no volume de diálogos, com variações que provavelmente refletem diferenças na complexidade narrativa de cada episódio.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def interpret_token_stats(stats):\n",
    "    markdown_text = f\"\"\"\n",
    "## Análise Descritiva dos Tokens nos Episódios de The Simpsons\n",
    "\n",
    "### Visão Geral Estatística\n",
    "- **Número Total de Episódios Analisados**: {stats['count']}\n",
    "- **Média de Tokens por Episódio**: {stats['mean']:.2f} tokens\n",
    "- **Desvio Padrão**: {stats['std']:.2f} tokens\n",
    "\n",
    "### Distribuição de Tokens\n",
    "- **Mínimo**: {stats['min']:.0f} tokens\n",
    "- **Máximo**: {stats['max']:.0f} tokens\n",
    "- **Mediana (50%)**: {stats['50%']:.2f} tokens\n",
    "\n",
    "### Interpretação Detalhada\n",
    "1. **Consistência Narrativa**\n",
    "   - A pequena variação no desvio padrão (cerca de {(stats['std']/stats['mean']*100):.1f}% da média) sugere uma consistência significativa no tamanho dos diálogos entre os episódios.\n",
    "\n",
    "2. **Amplitude de Variação**\n",
    "   - Existe uma variação considerável entre o episódio mais curto ({stats['min']:.0f} tokens) e o mais longo ({stats['max']:.0f} tokens), representando uma diferença de quase {stats['max']/stats['min']:.1f} vezes.\n",
    "\n",
    "3. **Distribuição Simétrica**\n",
    "   - A proximidade entre média ({stats['mean']:.2f}) e mediana ({stats['50%']:.2f}) indica uma distribuição relativamente simétrica dos tokens.\n",
    "\n",
    "4. **Quartis**\n",
    "   - 25% dos episódios têm até {stats['25%']:.0f} tokens\n",
    "   - 75% dos episódios têm até {stats['75%']:.0f} tokens\n",
    "\n",
    "### Conclusão\n",
    "Os episódios de The Simpsons mantêm uma notável consistência no volume de diálogos, com variações que provavelmente refletem diferenças na complexidade narrativa de cada episódio.\n",
    "\"\"\"\n",
    "    display(Markdown(markdown_text))\n",
    "\n",
    "# Chamar a função com as estatísticas\n",
    "interpret_token_stats(episode_tokens['tokens'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar API do Google\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel('gemini-1.5-pro')\n",
    "\n",
    "# Preparar dados para análise\n",
    "df_ratings = data[['episode_season', 'episode_title', 'episode_imdb_rating', 'episode_us_viewers_in_millions']].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de Prompt Chaining\n",
    "def prompt_chain_imdb_analysis(df):\n",
    "    # Justificativa dos Prompts:\n",
    "    # 1. Primeiro prompt: Análise estatística descritiva para estabelecer contexto\n",
    "    # 2. Segundo prompt: Análise de tendências por temporada para identificar padrões evolutivos\n",
    "    # 3. Terceiro prompt: Correlação entre audiência e avaliações para insights mais profundos\n",
    "\n",
    "    # Prompt 1: Análise Estatística Descritiva\n",
    "    prompt1 = f\"\"\"\n",
    "    Análise estatística das avaliações de IMDB de The Simpsons:\n",
    "    \n",
    "    Dados de entrada:\n",
    "    - Total de episódios: {len(df)}\n",
    "    - Média de avaliação IMDB: {df['episode_imdb_rating'].mean():.2f}\n",
    "    - Mediana de avaliação: {df['episode_imdb_rating'].median():.2f}\n",
    "    - Desvio padrão: {df['episode_imdb_rating'].std():.2f}\n",
    "    - Mínima avaliação: {df['episode_imdb_rating'].min():.2f}\n",
    "    - Máxima avaliação: {df['episode_imdb_rating'].max():.2f}\n",
    "\n",
    "    Forneça uma análise detalhada sobre a distribuição das avaliações, destacando:\n",
    "    1. Significado estatístico das variações\n",
    "    2. Possíveis fatores que influenciam as notas\n",
    "    3. Interpretação da qualidade geral da série\n",
    "    \"\"\"\n",
    "\n",
    "    response1 = model.generate_content(prompt1)\n",
    "    \n",
    "    # Prompt 2: Análise de Tendências por Temporada\n",
    "    season_ratings = df.groupby('episode_season')['episode_imdb_rating'].agg(['mean', 'min', 'max'])\n",
    "    prompt2 = f\"\"\"\n",
    "    Análise de tendências de avaliações por temporada de The Simpsons:\n",
    "    \n",
    "    Dados de avaliação por temporada:\n",
    "    {season_ratings}\n",
    "\n",
    "    Analise:\n",
    "    1. Evolução da qualidade ao longo das temporadas\n",
    "    2. Temporadas com melhores e piores avaliações\n",
    "    3. Possíveis razões para variações nas notas entre temporadas\n",
    "    4. Pontos de inflexão na qualidade da série\n",
    "    \"\"\"\n",
    "\n",
    "    response2 = model.generate_content(prompt2)\n",
    "    \n",
    "    # Prompt 3: Análise Comparativa de Audiência e Avaliações\n",
    "    correlation = df['episode_imdb_rating'].corr(df['episode_us_viewers_in_millions'])\n",
    "    prompt3 = f\"\"\"\n",
    "    Análise da relação entre audiência e avaliações de IMDB:\n",
    "    \n",
    "    Dados:\n",
    "    - Correlação entre avaliações IMDB e audiência: {correlation:.2f}\n",
    "    - Média de visualizações: {df['episode_us_viewers_in_millions'].mean():.2f} milhões\n",
    "    - Média de avaliação IMDB: {df['episode_imdb_rating'].mean():.2f}\n",
    "\n",
    "    Investigue:\n",
    "    1. Relação entre qualidade (IMDB) e audiência\n",
    "    2. Impacto da popularidade nas avaliações\n",
    "    3. Variações de audiência ao longo das temporadas\n",
    "    4. Fatores que podem explicar a correlação observada\n",
    "    \"\"\"\n",
    "\n",
    "    response3 = model.generate_content(prompt3)\n",
    "    \n",
    "    return {\n",
    "        'estatistica_descritiva': response1.text,\n",
    "        'tendencias_temporadas': response2.text,\n",
    "        'analise_audiencia': response3.text\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pergunta 2: Utilize a técnica de Prompt Chaining para fazer uma análise descritiva das avaliações do IMDB e da audiência dos episódios. Justifique os prompts gerados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Estatistica Descritiva ---\n",
      "## Análise Estatística das Avaliações IMDB de The Simpsons\n",
      "\n",
      "Os dados fornecidos permitem uma análise interessante da recepção dos episódios de The Simpsons pelo público do IMDB.\n",
      "\n",
      "**1. Significado Estatístico das Variações:**\n",
      "\n",
      "* **Média (7.42):** Uma média de 7.42 em 10 indica uma recepção geralmente positiva da série.  Em termos gerais, isso sugere que a maioria dos episódios é considerada boa ou muito boa.\n",
      "* **Mediana (7.30):**  A mediana ser ligeiramente inferior à média (7.30) sugere uma leve assimetria à esquerda na distribuição. Isso implica que há mais episódios com notas abaixo da média do que acima, possivelmente devido à presença de alguns episódios com notas consideravelmente baixas que puxam a média para baixo, sem afetar tanto a mediana.\n",
      "* **Desvio Padrão (0.73):** Um desvio padrão de 0.73 indica uma variabilidade moderada nas avaliações. Isso significa que a maioria das notas se concentra em torno da média (7.42), com uma dispersão relativamente pequena.  A maioria dos episódios deve ter notas entre 6.69 e 8.15 (média ± desvio padrão).\n",
      "* **Mínima (4.50) e Máxima (9.20):** A amplitude considerável entre a nota mínima e máxima (4.7 pontos) reforça a ideia de variabilidade, mostrando que existem episódios considerados significativamente melhores e piores do que a média. A nota máxima de 9.2 indica a existência de episódios aclamados, enquanto a mínima de 4.5 aponta para a presença de episódios que desagradaram uma parcela significativa do público.\n",
      "\n",
      "**2. Possíveis Fatores que Influenciam as Notas:**\n",
      "\n",
      "Vários fatores podem contribuir para as variações nas notas de The Simpsons:\n",
      "\n",
      "* **Qualidade da escrita:** Episódios com roteiros mais fracos, piadas repetitivas ou enredos previsíveis tendem a receber notas mais baixas.\n",
      "* **Participações especiais:** Episódios com celebridades convidadas populares podem receber um impulso nas avaliações.\n",
      "* **Temas abordados:** Episódios que tratam de temas controversos ou que não ressoam com o público podem ter notas mais baixas.\n",
      "* **Nostalgia:** Episódios mais antigos, associados à \"Era de Ouro\" da série, podem ser avaliados com mais generosidade devido à nostalgia.\n",
      "* **Mudanças na equipe criativa:** A saída de roteiristas ou produtores importantes pode impactar a qualidade da série e, consequentemente, as avaliações.\n",
      "* **Evolução do humor:** O humor de The Simpsons pode não ter envelhecido bem para alguns espectadores, levando a notas mais baixas em episódios antigos.\n",
      "* **Viés de avaliação:** Fatores subjetivos, como humor pessoal e expectativas do espectador, sempre influenciam as avaliações.\n",
      "\n",
      "**3. Interpretação da Qualidade Geral da Série:**\n",
      "\n",
      "Apesar da variabilidade e da presença de episódios com notas baixas, a média de 7.42 e a mediana de 7.30 demonstram uma qualidade geral alta para The Simpsons ao longo de suas muitas temporadas.  A série claramente ressoou com uma grande audiência e manteve um nível de popularidade considerável.\n",
      "\n",
      "A existência de episódios com notas mais baixas é esperada em uma série com tantos episódios.  A longevidade da série pode ter contribuído para uma queda na qualidade em algumas temporadas, o que é refletido nas avaliações. No entanto, a presença de episódios com notas altas, chegando a 9.2, demonstra que a série ainda é capaz de produzir conteúdo de alta qualidade.\n",
      "\n",
      "Em resumo, a análise estatística das avaliações do IMDB sugere que The Simpsons, apesar de suas flutuações, mantém-se como uma série de qualidade, com uma base de fãs dedicada e uma história de sucesso na televisão. A variabilidade nas notas reflete a evolução da série ao longo do tempo e a diversidade de opiniões entre os espectadores.\n",
      "\n",
      "\n",
      "--- Tendencias Temporadas ---\n",
      "**Análise de Tendências de Avaliações de The Simpsons por Temporada**\n",
      "\n",
      "Os dados fornecidos mostram uma clara tendência de declínio na avaliação média de *The Simpsons* ao longo das suas temporadas. Vamos analisar os pontos solicitados:\n",
      "\n",
      "**1. Evolução da Qualidade ao Longo das Temporadas:**\n",
      "\n",
      "* **Era de Ouro (Temporadas 1-9):** As primeiras temporadas apresentam as médias mais altas, com um pico na temporada 5 (8.34).  Observa-se uma queda gradual a partir da temporada 9, marcando o fim do que muitos consideram a \"era de ouro\" da série.\n",
      "* **Declínio Gradual (Temporadas 10-26):** A partir da temporada 10, a média cai abaixo de 8 e continua em declínio, estabilizando-se em torno de 6.7-6.8 nas últimas temporadas apresentadas.\n",
      "\n",
      "**2. Temporadas com Melhores e Piores Avaliações:**\n",
      "\n",
      "* **Melhores:** Temporada 5 (8.34), Temporada 4 (8.27) e Temporada 3 (8.15)\n",
      "* **Piores:** Temporada 13 (7.14), Temporada 23 (6.81), Temporada 20, 21, 22 e 24 todas com médias inferiores a 6.9.\n",
      "\n",
      "**3. Possíveis Razões para Variações nas Notas entre Temporadas:**\n",
      "\n",
      "* **Mudanças na Equipe Criativa:** A saída de roteiristas e produtores chave ao longo dos anos pode ter impactado a qualidade e o estilo do humor da série.\n",
      "* **Exaustão Criativa:** Manter a originalidade e o frescor em uma série com tantas temporadas é um desafio.  Piadas repetitivas e enredos previsíveis podem ter contribuído para a queda nas avaliações.\n",
      "* **Mudanças Culturais:** O humor e as referências culturais evoluem. O que era considerado engraçado nos anos 90 pode não ter o mesmo impacto hoje.\n",
      "* **Fator Nostalgia:** As primeiras temporadas se beneficiam do fator nostalgia para muitos fãs, que as associam à sua infância e adolescência.\n",
      "* **Evolução dos Personagens:**  Alguns fãs argumentam que a personalidade de certos personagens mudou com o tempo, tornando-os menos interessantes ou até mesmo irritantes.\n",
      "* **Quantidade vs. Qualidade:** Com tantas temporadas, é natural que haja uma maior variação na qualidade dos episódios.\n",
      "\n",
      "**4. Pontos de Inflexão na Qualidade da Série:**\n",
      "\n",
      "* **Temporada 9:** Marca o início do declínio mais perceptível nas avaliações, representando uma transição da era de ouro para um período de menor aclamação.\n",
      "* **Temporada 13:** Atingindo uma média próxima a 7,1, representa uma queda significativa e um novo patamar inferior de avaliações.\n",
      "* **Temporadas 20 em diante:** As avaliações se estabilizam em um nível mais baixo, sugerindo uma possível aceitação por parte do público remanescente da qualidade atual da série.\n",
      "\n",
      "\n",
      "**Considerações Adicionais:**\n",
      "\n",
      "É importante lembrar que esses dados representam apenas uma perspectiva da qualidade da série. Outros fatores, como audiência e impacto cultural, também devem ser considerados. A longevidade de *The Simpsons* é um testemunho de sua relevância cultural, mesmo com a flutuação nas avaliações.  Seria interessante analisar também a dispersão das notas (desvio padrão) dentro de cada temporada, para entender a consistência da qualidade dos episódios.  A nota mínima de 4.5 na temporada 23 sugere a existência de episódios particularmente mal recebidos.\n",
      "\n",
      "\n",
      "--- Analise Audiencia ---\n",
      "## Análise da Relação entre Audiência e Avaliações IMDB\n",
      "\n",
      "Dada a correlação de 0.61 entre avaliações IMDB e audiência, podemos inferir que existe uma relação moderadamente forte e positiva entre as duas variáveis. Isso significa que, em geral, filmes/séries com avaliações IMDB mais altas tendem a ter maior audiência, e vice-versa. No entanto, é crucial lembrar que correlação não implica causalidade.\n",
      "\n",
      "**1. Relação entre Qualidade (IMDB) e Audiência:**\n",
      "\n",
      "A correlação positiva sugere que a qualidade percebida, refletida nas avaliações IMDB, influencia a audiência. Um filme/série bem avaliado, provavelmente por apresentar bom roteiro, atuações convincentes, direção competente, etc., tende a atrair mais espectadores.  No entanto, a correlação não é perfeita (1.0), indicando que outros fatores além da qualidade influenciam a audiência.\n",
      "\n",
      "**2. Impacto da Popularidade nas Avaliações:**\n",
      "\n",
      "A popularidade, medida pela audiência, também pode influenciar as avaliações IMDB.  O \"efeito bandwagon\" pode levar pessoas a avaliar positivamente um filme/série simplesmente porque é popular.  A visibilidade aumentada de produções populares também pode resultar em um número maior de avaliações, potencialmente enviesando a média para cima ou para baixo dependendo da recepção geral. Filmes/séries com grande marketing e divulgação podem atrair grande audiência inicialmente, independentemente da qualidade, e isso pode influenciar as avaliações iniciais.\n",
      "\n",
      "**3. Variações de Audiência ao Longo das Temporadas:**\n",
      "\n",
      "A análise da variação de audiência ao longo das temporadas pode fornecer insights valiosos. Uma queda na audiência, mesmo com avaliações IMDB consistentes, pode indicar problemas como:\n",
      "\n",
      "* **Fadiga da narrativa:** Histórias repetitivas ou que se arrastam podem levar à perda de interesse.\n",
      "* **Mudanças no elenco/equipe:** A saída de personagens ou criadores populares pode afastar fãs.\n",
      "* **Concorrência:** O surgimento de novas séries/filmes pode dividir a atenção do público.\n",
      "* **Marketing ineficaz:**  A falta de promoção adequada para novas temporadas pode prejudicar a audiência.\n",
      "\n",
      "Por outro lado, um aumento na audiência ao longo das temporadas pode indicar:\n",
      "\n",
      "* **Melhora na qualidade:** Aprimoramentos na escrita, direção ou atuação podem atrair novos espectadores e fidelizar os antigos.\n",
      "* **\"Boca a boca\" positivo:** Recomendações de outros espectadores podem impulsionar a audiência.\n",
      "* **Marketing eficaz:** Campanhas publicitárias bem-sucedidas podem gerar interesse e expectativa.\n",
      "\n",
      "**4. Fatores que Podem Explicar a Correlação Observada:**\n",
      "\n",
      "Além da qualidade e popularidade, outros fatores podem contribuir para a correlação entre avaliações IMDB e audiência:\n",
      "\n",
      "* **Gênero:**  Certos gêneros, como ação e comédia, podem atrair um público maior do que outros, como dramas ou filmes de arte.\n",
      "* **Elenco:** A presença de atores famosos pode impulsionar tanto a audiência quanto as avaliações.\n",
      "* **Orçamento e produção:** Filmes/séries com alto orçamento geralmente apresentam efeitos visuais e produção de alta qualidade, o que pode atrair espectadores e influenciar positivamente as avaliações.\n",
      "* **Disponibilidade e plataforma de distribuição:** A facilidade de acesso a um filme/série, seja em streaming, cinema ou TV aberta, impacta diretamente a audiência.  Plataformas populares com grande base de usuários tendem a gerar maior visibilidade.\n",
      "* **Críticas da mídia especializada:** Avaliações positivas de críticos renomados podem influenciar a percepção do público e as avaliações IMDB.\n",
      "\n",
      "Para uma análise mais aprofundada, seria necessário investigar a influência de cada um desses fatores individualmente e em conjunto.  A inclusão de outras variáveis, como orçamento, gênero e dados demográficos da audiência, permitiria construir modelos estatísticos mais robustos e compreender melhor a complexa relação entre audiência e avaliações IMDB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Executar análise\n",
    "resultados = prompt_chain_imdb_analysis(df_ratings)\n",
    "\n",
    "# Visualização de Distribuição de Avaliações\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_ratings['episode_imdb_rating'], bins=20, edgecolor='black')\n",
    "plt.title('Distribuição das Avaliações de IMDB')\n",
    "plt.xlabel('Nota IMDB')\n",
    "plt.ylabel('Número de Episódios')\n",
    "plt.show()\n",
    "\n",
    "# Salvar resultados\n",
    "with open('simpsons_analysis_results.txt', 'w', encoding='utf-8') as f:\n",
    "    for chave, valor in resultados.items():\n",
    "        f.write(f\"\\n--- {chave.replace('_', ' ').title()} ---\\n\")\n",
    "        f.write(valor)\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "# Imprimir resultados\n",
    "for chave, valor in resultados.items():\n",
    "    print(f\"\\n--- {chave.replace('_', ' ').title()} ---\")\n",
    "    print(valor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Classificação de Sentimento com Few-Shot Learning\n",
    "\n",
    "Implemente um modelo de classificação de sentimentos em Python para categorizar trechos de diálogo dos Simpsons como “Positivo”, “Neutro” ou “Negativo”. Use a técnica de few-shot learning, incluindo 5 exemplos por categoria no prompt. Selecione o episódio número 92 (episode_id) da temporada 5 (episode_season). Utilize a técnica de batch-prompting para classificar múltiplas falas num único prompt. Responda às perguntas:\n",
    "\n",
    "* Quantas chamadas ao LLM foram necessárias?\n",
    "* Qual é a distribuição de fala por categoria?\n",
    "* Avaliando 5 falas de cada classe, qual é a acurácia do modelo?\n",
    "* Qual foi a precisão do modelo para cada classe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Número de diálogos encontrados: 277\n",
      "1. Quantas chamadas ao LLM foram necessárias?\n",
      "1\n",
      "\n",
      "2. Distribuição de fala por categoria:\n",
      "Positive: 23 (8.30%)\n",
      "Neutral: 16 (5.78%)\n",
      "Negative: 58 (20.94%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variáveis de ambiente\n",
    "load_dotenv()\n",
    "\n",
    "# Configurar API do Google\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "\n",
    "# Modelo Gemini\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def sentiment_classification_with_few_shot(dialogs):\n",
    "    # Exemplos few-shot para cada categoria\n",
    "    few_shot_examples = {\n",
    "        'Positive': [\n",
    "            \"This is the best day ever!\",\n",
    "            \"I'm so happy and excited!\",\n",
    "            \"Wonderful news, everyone!\",\n",
    "            \"What an amazing achievement!\",\n",
    "            \"I can't believe how great this is!\"\n",
    "        ],\n",
    "        'Neutral': [\n",
    "            \"I see what you mean.\",\n",
    "            \"That's interesting.\",\n",
    "            \"So, what happened next?\",\n",
    "            \"Just another day in Springfield.\",\n",
    "            \"I'm not sure about that.\"\n",
    "        ],\n",
    "        'Negative': [\n",
    "            \"This is absolutely terrible.\",\n",
    "            \"I'm so frustrated right now.\",\n",
    "            \"Everything is going wrong.\",\n",
    "            \"What a disaster!\",\n",
    "            \"I can't stand this anymore.\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Construir prompt com exemplos few-shot\n",
    "    prompt = \"Classify the sentiment of the following dialogues as 'Positive', 'Neutral', or 'Negative'.\\n\\n\"\n",
    "    \n",
    "    # Adicionar exemplos\n",
    "    for sentiment, examples in few_shot_examples.items():\n",
    "        prompt += f\"Examples of {sentiment} sentiment:\\n\"\n",
    "        for ex in examples:\n",
    "            prompt += f\"- '{ex}': {sentiment}\\n\"\n",
    "        prompt += \"\\n\"\n",
    "    \n",
    "    # Adicionar diálogos para classificação\n",
    "    prompt += \"New dialogues to classify:\\n\"\n",
    "    for dialog in dialogs:\n",
    "        prompt += f\"- '{dialog}'\\n\"\n",
    "    \n",
    "    # Instrução final\n",
    "    prompt += \"\\nList the sentiment for each dialogue in order.\"\n",
    "    \n",
    "    # Fazer chamada ao modelo\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text, 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Erro na classificação: {e}\")\n",
    "        return \"\", 0\n",
    "\n",
    "def analyze_simpsons_sentiment(episode_id, episode_season, data):\n",
    "    # Filtrar diálogos do episódio específico\n",
    "    episode_dialogs = data[\n",
    "        (data['episode_id'] == episode_id) & \n",
    "        (data['episode_season'] == episode_season)\n",
    "    ]['spoken_words'].tolist()\n",
    "    \n",
    "    # Verificar número de diálogos\n",
    "    print(f\"\\nNúmero de diálogos encontrados: {len(episode_dialogs)}\")\n",
    "    \n",
    "    # Classificar sentimentos\n",
    "    sentiment_text, llm_calls = sentiment_classification_with_few_shot(episode_dialogs)\n",
    "    \n",
    "    # Contar sentimentos\n",
    "    sentiment_distribution = {\n",
    "        'Positive': sentiment_text.count('Positive'),\n",
    "        'Neutral': sentiment_text.count('Neutral'),\n",
    "        'Negative': sentiment_text.count('Negative')\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'LLM_Calls': llm_calls,\n",
    "        'Sentiment_Distribution': sentiment_distribution,\n",
    "        'Total_Dialogs': len(episode_dialogs)\n",
    "    }\n",
    "\n",
    "# Executar análise\n",
    "resultado = analyze_simpsons_sentiment(episode_id=92, episode_season=5, data=data)\n",
    "\n",
    "# Respostas formatadas\n",
    "print(\"1. Quantas chamadas ao LLM foram necessárias?\")\n",
    "print(resultado['LLM_Calls'])\n",
    "\n",
    "print(\"\\n2. Distribuição de fala por categoria:\")\n",
    "for categoria, quantidade in resultado['Sentiment_Distribution'].items():\n",
    "    porcentagem = (quantidade / resultado['Total_Dialogs']) * 100\n",
    "    print(f\"{categoria}: {quantidade} ({porcentagem:.2f}%)\")\n",
    "\n",
    "# Criar DataFrame com os resultados\n",
    "results_df = pd.DataFrame([\n",
    "    ['Total Diálogos', resultado['Total_Dialogs'], '100%'],\n",
    "    ['Chamadas LLM', resultado['LLM_Calls'], '-'],\n",
    "    ['Positive', resultado['Sentiment_Distribution']['Positive'], \n",
    "     f\"{(resultado['Sentiment_Distribution']['Positive'] / resultado['Total_Dialogs']) * 100:.2f}%\"],\n",
    "    ['Neutral', resultado['Sentiment_Distribution']['Neutral'], \n",
    "     f\"{(resultado['Sentiment_Distribution']['Neutral'] / resultado['Total_Dialogs']) * 100:.2f}%\"],\n",
    "    ['Negative', resultado['Sentiment_Distribution']['Negative'], \n",
    "     f\"{(resultado['Sentiment_Distribution']['Negative'] / resultado['Total_Dialogs']) * 100:.2f}%\"]\n",
    "], columns=['Métrica', 'Quantidade', 'Percentual'])\n",
    "\n",
    "# Salvar como CSV\n",
    "results_df.to_csv('analise_sentimentos.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Resumo Episódio\n",
    "\n",
    "Assista ao episódio “Homer, o vigilante” (ou leia as falas dos personagens), número 92 (episode_id) da temporada 5 (episode_season) e faça um resumo de aproximadamente 500 tokens (meça a quantidade usando o modelo do exercício 5), explicando o que acontece e como termina o episódio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo diálogos do episódio...\n",
      "Encontrados 277 diálogos.\n",
      "\n",
      "Gerando resumo...\n",
      "Contando tokens...\n",
      "\n",
      "==================================================\n",
      "🎬 Resumo do Episódio 'Homer, o Vigilante' (Temporada 5, Episódio 92):\n",
      "\n",
      "**Resumo Profissional**\n",
      "\n",
      "**Eventos Principais:**\n",
      "\n",
      "* Ocorre uma onda de assaltos em Springfield, incluindo a casa dos Simpsons.\n",
      "* Os moradores formam uma patrulha do bairro liderada por Homer Simpson.\n",
      "* O chefe de polícia descobre uma pista que aponta para a delegacia de polícia.\n",
      "* O Cat Burglar é revelado como o responsável pelos roubos.\n",
      "* Homer e a patrulha do bairro enfrentam o Cat Burglar.\n",
      "\n",
      "**Desenvolvimento da Narrativa:**\n",
      "\n",
      "* A série de assaltos cria pânico na comunidade.\n",
      "* Homer e os vigilantes são inicialmente bem-sucedidos em lidar com pequenos crimes.\n",
      "* No entanto, seu abuso de poder e métodos violentos geram preocupações.\n",
      "* A investigação policial revela uma conexão suspeita entre o Cat Burglar e a delegacia.\n",
      "* Homer se compromete a recuperar o saxofone de Lisa roubado pelo Cat Burglar.\n",
      "\n",
      "**Conclusão:**\n",
      "\n",
      "* O Cat Burglar é preso e o saxofone de Lisa é recuperado.\n",
      "* Os vigilantes são dissolvidos devido ao uso excessivo de força.\n",
      "* Homer reflete sobre seu papel como líder da patrulha do bairro e o abuso de poder que pode acompanhar o vigilantismo.\n",
      "\n",
      "📊 Número de tokens: 299\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import tiktoken\n",
    "\n",
    "# Configuração inicial\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def extract_episode_dialogs(df, episode_id, episode_season):\n",
    "    \"\"\"Extrair diálogos de um episódio específico\"\"\"\n",
    "    return df[\n",
    "        (df['episode_id'].astype(str) == str(episode_id)) & \n",
    "        (df['episode_season'].astype(str) == str(episode_season))\n",
    "    ]\n",
    "\n",
    "def generate_episode_summary(dialogs):\n",
    "    \"\"\"Gerar resumo do episódio com foco na narrativa\"\"\"\n",
    "    try:\n",
    "        # Tratar diálogos nulos e concatenar\n",
    "        all_dialogs = \" \".join(\n",
    "            dialogs['spoken_words']\n",
    "            .fillna('')\n",
    "            .astype(str)\n",
    "            .tolist()\n",
    "        )[:8000]  # Reduzindo o tamanho para evitar problemas\n",
    "        \n",
    "        # Prompt focado em narrativa\n",
    "        prompt = f\"\"\"Crie um resumo profissional do seguinte conteúdo narrativo, \n",
    "        destacando os principais elementos da história de forma objetiva.\n",
    "\n",
    "        Por favor, descreva:\n",
    "        1. Eventos principais\n",
    "        2. Desenvolvimento da narrativa\n",
    "        3. Conclusão\n",
    "\n",
    "        Conteúdo: {all_dialogs}\"\"\"\n",
    "        \n",
    "        # Tentar gerar o resumo\n",
    "        try:\n",
    "            response = model.generate_content(prompt)\n",
    "            if hasattr(response, 'text'):\n",
    "                return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Primeira tentativa falhou: {str(e)}\")\n",
    "            \n",
    "            # Segunda tentativa com prompt mais simples\n",
    "            simple_prompt = f\"\"\"Resuma os principais eventos desta história:\n",
    "\n",
    "            História: {all_dialogs[:5000]}\"\"\"\n",
    "            \n",
    "            response = model.generate_content(simple_prompt)\n",
    "            return response.text if hasattr(response, 'text') else \"Não foi possível gerar o resumo.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar resumo: {str(e)}\")\n",
    "        return \"Não foi possível processar o resumo do episódio.\"\n",
    "\n",
    "def count_tokens(text):\n",
    "    \"\"\"Contar tokens\"\"\"\n",
    "    return len(encoder.encode(text))\n",
    "\n",
    "try:\n",
    "    # Executar análise\n",
    "    print(\"Extraindo diálogos do episódio...\")\n",
    "    episode_dialogs = extract_episode_dialogs(data, episode_id=92, episode_season=5)\n",
    "    \n",
    "    if len(episode_dialogs) == 0:\n",
    "        print(\"Nenhum diálogo encontrado para o episódio especificado.\")\n",
    "    else:\n",
    "        print(f\"Encontrados {len(episode_dialogs)} diálogos.\")\n",
    "        \n",
    "        print(\"\\nGerando resumo...\")\n",
    "        summary = generate_episode_summary(episode_dialogs)\n",
    "        \n",
    "        print(\"Contando tokens...\")\n",
    "        token_count = count_tokens(summary)\n",
    "\n",
    "        # Saída formatada\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"🎬 Resumo do Episódio 'Homer, o Vigilante' (Temporada 5, Episódio 92):\")\n",
    "        print(\"\\n\" + summary)\n",
    "        print(\"\\n📊 Número de tokens:\", token_count)\n",
    "        print(\"=\"*50)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro durante a execução: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Resumos Complexos com Chunks de Texto\n",
    "\n",
    "Crie um prompt para resumir o episódio número 92 (episode_id) da temporada 5 (episode_season) usando o princípio de divisão para contornar limitações de tokens. Utilize o processo de chunks para separar o episódio em janelas de 100 falas, com sobreposição de 25 falas por janela. Utilize o LLM para resumir cada um dos chunks. Posteriormente, crie um segundo prompt com os resumos dos chunks instruindo o LLM a gerar o resumo final. Quantos chunks foram necessários? Avalie o resultado do resumo final e de cada chunk quanto à veracidade e coerência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Iniciando processamento do episódio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Extraindo diálogos para episódio 92 temporada 5\n",
      "INFO:__main__:Criados 4 chunks\n",
      "INFO:__main__:Processando chunk 1/4\n",
      "INFO:__main__:Processando chunk 2/4\n",
      "WARNING:__main__:Erro na tentativa 1: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: MEDIUM\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: NEGLIGIBLE\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_HATE_SPEECH\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_HARASSMENT\n",
      "probability: MEDIUM\n",
      ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "probability: NEGLIGIBLE\n",
      "])\n",
      "WARNING:__main__:Erro na tentativa 2: (\"Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 3. The candidate's safety_ratings are: [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HATE_SPEECH\\nprobability: NEGLIGIBLE\\n, category: HARM_CATEGORY_HARASSMENT\\nprobability: MEDIUM\\n, category: HARM_CATEGORY_DANGEROUS_CONTENT\\nprobability: NEGLIGIBLE\\n].\", [category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_HATE_SPEECH\n",
      "probability: NEGLIGIBLE\n",
      ", category: HARM_CATEGORY_HARASSMENT\n",
      "probability: MEDIUM\n",
      ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "probability: NEGLIGIBLE\n",
      "])\n",
      "INFO:__main__:Processando chunk 3/4\n",
      "INFO:__main__:Processando chunk 4/4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados ===\n",
      "\n",
      "Número de chunks: 4\n",
      "\n",
      "--- Resumos dos Chunks ---\n",
      "\n",
      "Chunk 1:\n",
      "**Resumo:**\n",
      "\n",
      "Em Springfield, diversas casas foram roubadas pelo \"Springfield Cat Burglar\". Os Simpsons perderam o saxofone de Lisa, uma TV portátil e um colar. O chefe Wiggum investiga e descobre que as cenas de crime formam uma seta apontando para a delegacia.\n",
      "\n",
      "Um cão farejador é usado para rastrear o ladrão, mas fracassa. Enquanto isso, Homer compra um sistema de segurança de alta tecnologia para sua casa.\n",
      "\n",
      "Frustrado, Homer decide formar uma patrulha do bairro. Os moradores o elegem como líder, apesar de sua falta de experiência, pois acreditam que ele é um homem de ação.\n",
      "==================================================\n",
      "\n",
      "Chunk 2:\n",
      "Em um episódio dos Simpsons, Homer e um grupo de homens formam um grupo vigilante. Os amigos de Homer o apoiam, exceto Marge, que se preocupa com a segurança. Apesar das objeções de Marge, Homer e seus companheiros adotam codinomes e decidem patrulhar a cidade. Eles usam um dispositivo misterioso para assustar os moradores, mas acabam causando mais caos. Bart e Lisa ficam preocupados com as ações do pai, enquanto Marge tenta detê-lo.\n",
      "==================================================\n",
      "\n",
      "Chunk 3:\n",
      "Na tentativa de roubar a maior zircônia cúbica do Museu de Springfield, um ladrão desafia o policial Homer Simpson a capturá-lo.\n",
      "\n",
      "Homer, auxiliado por seu pai Abe, investiga e descobre que o ladrão é Molloy, um residente de sua casa de repouso.\n",
      "\n",
      "Molloy é preso e devolve os objetos roubados, conquistando a simpatia dos cidadãos. No entanto, o chefe Wiggum o prende, pois quebrar a lei deve ser punido.\n",
      "\n",
      "Ao ser questionado sobre o paradeiro de milhões de dólares roubados ao longo dos anos, Molloy indica que eles estão enterrados em Springfield, sob um \"Big T\".\n",
      "==================================================\n",
      "\n",
      "Chunk 4:\n",
      "Os Simpsons seguem uma pista que afirma haver um tesouro enterrado em um endereço específico. Eles seguem as instruções e chegam ao local, apenas para descobrir que é uma pista falsa plantada por um vigarista que escapou da prisão. O grupo fica desapontado e tenta encontrar uma saída cavando, mas depois de muita escavação, eles percebem que não conseguirão escapar dessa forma.\n",
      "==================================================\n",
      "\n",
      "--- Resumo Final ---\n",
      "Em Springfield, uma onda de assaltos leva os moradores a formar uma vigilância liderada por Homer Simpson. No entanto, a patrulha do bairro logo causa caos com seu dispositivo de susto.\n",
      "\n",
      "Enquanto isso, o inspetor Wiggum investiga os roubos e descobre uma seta formada pelas cenas de crime apontando para a delegacia. Um cão farejador falha em rastrear o ladrão, levando Homer a assumir o caso.\n",
      "\n",
      "Guiado por uma pista, Homer e Abe Simpson descobrem que o ladrão é Molloy, um residente de sua casa de repouso. Ao tentar roubar a zircônia cúbica do Museu de Springfield, Molloy é preso por Homer.\n",
      "\n",
      "Molloy indica que milhões de dólares roubados estão enterrados sob um \"Big T\" em Springfield. Os Simpsons seguem a pista, mas descobrem que é uma armadilha. Desesperados, eles tentam cavar para escapar, mas percebem que não conseguirão.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuração da API\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "def extract_episode_dialogs(data, episode_id, episode_season):\n",
    "    \"\"\"Extrair diálogos de um episódio específico\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Extraindo diálogos para episódio {episode_id} temporada {episode_season}\")\n",
    "        \n",
    "        episode_dialogs = data[\n",
    "            (data['episode_id'].astype(str) == str(episode_id)) & \n",
    "            (data['episode_season'].astype(str) == str(episode_season))\n",
    "        ]\n",
    "        \n",
    "        if episode_dialogs.empty:\n",
    "            logger.warning(\"Nenhum diálogo encontrado\")\n",
    "            return []\n",
    "            \n",
    "        dialogs = episode_dialogs['spoken_words'].fillna('').astype(str).tolist()\n",
    "        return [d.strip() for d in dialogs if d.strip()]\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao extrair diálogos: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def create_chunks(dialogs, chunk_size=100, overlap=25):\n",
    "    \"\"\"Criar chunks de diálogo\"\"\"\n",
    "    try:\n",
    "        if not dialogs:\n",
    "            return 0, []\n",
    "            \n",
    "        chunks = []\n",
    "        step = chunk_size - overlap\n",
    "        \n",
    "        for i in range(0, len(dialogs), step):\n",
    "            chunk = dialogs[i:i + chunk_size]\n",
    "            if len(chunk) >= 5:\n",
    "                chunks.append(chunk)\n",
    "                \n",
    "        logger.info(f\"Criados {len(chunks)} chunks\")\n",
    "        return len(chunks), chunks\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao criar chunks: {str(e)}\")\n",
    "        return 0, []\n",
    "\n",
    "def summarize_chunk(chunk, retry_count=3):\n",
    "    \"\"\"Resumir chunk com tratamento robusto de erros\"\"\"\n",
    "    for attempt in range(retry_count):\n",
    "        try:\n",
    "            # Limitar tamanho do texto para evitar problemas\n",
    "            chunk_text = \" \".join(chunk[:75])  # Limitado a 75 falas\n",
    "            \n",
    "            # Primeira tentativa com prompt detalhado\n",
    "            prompt = f\"\"\"Analise este trecho de um episódio dos Simpsons e crie um resumo objetivo.\n",
    "            Foque apenas nos eventos principais e interações entre personagens.\n",
    "            Mantenha um tom leve e apropriado para família.\n",
    "\n",
    "            Diálogo: {chunk_text}\"\"\"\n",
    "\n",
    "            response = model.generate_content(prompt)\n",
    "            if hasattr(response, 'text') and response.text:\n",
    "                return response.text\n",
    "                \n",
    "            # Segunda tentativa com prompt simplificado\n",
    "            if attempt > 0:\n",
    "                simple_prompt = f\"\"\"Resuma os principais acontecimentos deste trecho dos Simpsons:\n",
    "                {chunk_text}\"\"\"\n",
    "                \n",
    "                response = model.generate_content(simple_prompt)\n",
    "                if hasattr(response, 'text') and response.text:\n",
    "                    return response.text\n",
    "            \n",
    "            time.sleep(1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Erro na tentativa {attempt + 1}: {str(e)}\")\n",
    "            # Reduzir texto se houver erro\n",
    "            chunk = chunk[:(50 - attempt * 10)]  # Reduz progressivamente\n",
    "            time.sleep(1)\n",
    "    \n",
    "    return \"Não foi possível gerar um resumo para este segmento.\"\n",
    "\n",
    "def generate_final_summary(chunk_summaries):\n",
    "    \"\"\"Gerar resumo final integrado\"\"\"\n",
    "    try:\n",
    "        # Filtrar resumos válidos\n",
    "        valid_summaries = [s for s in chunk_summaries if \"Não foi possível\" not in s]\n",
    "        if not valid_summaries:\n",
    "            return \"Não há resumos válidos para processar.\"\n",
    "\n",
    "        summaries_text = \"\\n\".join(valid_summaries)\n",
    "        \n",
    "        prompt = f\"\"\"Crie um resumo coeso e completo deste episódio dos Simpsons \n",
    "        baseado nos seguintes resumos parciais:\n",
    "\n",
    "        {summaries_text}\n",
    "\n",
    "        Por favor, forneça um resumo que:\n",
    "        - Mantenha a sequência cronológica dos eventos\n",
    "        - Destaque os momentos principais\n",
    "        - Conecte os diferentes segmentos da história\"\"\"\n",
    "\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text if hasattr(response, 'text') else \"Erro ao gerar resumo final.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro no resumo final: {str(e)}\")\n",
    "        return \"Erro ao gerar o resumo final.\"\n",
    "\n",
    "def main(data, episode_id, episode_season):\n",
    "    \"\"\"Função principal com tratamento completo de erros\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Iniciando processamento do episódio\")\n",
    "        \n",
    "        # Extrair diálogos\n",
    "        dialogs = extract_episode_dialogs(data, episode_id, episode_season)\n",
    "        if not dialogs:\n",
    "            return {\n",
    "                \"num_chunks\": 0,\n",
    "                \"chunk_summaries\": [],\n",
    "                \"final_summary\": \"Nenhum diálogo encontrado para processar.\"\n",
    "            }\n",
    "        \n",
    "        # Criar chunks\n",
    "        num_chunks, chunks = create_chunks(dialogs)\n",
    "        if not chunks:\n",
    "            return {\n",
    "                \"num_chunks\": 0,\n",
    "                \"chunk_summaries\": [],\n",
    "                \"final_summary\": \"Erro ao criar chunks de diálogo.\"\n",
    "            }\n",
    "        \n",
    "        # Processar chunks\n",
    "        chunk_summaries = []\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            logger.info(f\"Processando chunk {i}/{num_chunks}\")\n",
    "            summary = summarize_chunk(chunk)\n",
    "            chunk_summaries.append(summary)\n",
    "            \n",
    "        # Gerar resumo final\n",
    "        final_summary = generate_final_summary(chunk_summaries)\n",
    "        \n",
    "        return {\n",
    "            \"num_chunks\": num_chunks,\n",
    "            \"chunk_summaries\": chunk_summaries,\n",
    "            \"final_summary\": final_summary\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro na execução principal: {str(e)}\")\n",
    "        return {\n",
    "            \"num_chunks\": 0,\n",
    "            \"chunk_summaries\": [],\n",
    "            \"final_summary\": f\"Erro durante o processamento: {str(e)}\"\n",
    "        }\n",
    "\n",
    "# Exemplo de uso\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Processar episódio\n",
    "        results = main(data, episode_id=92, episode_season=5)\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(\"\\n=== Resultados ===\")\n",
    "        print(f\"\\nNúmero de chunks: {results['num_chunks']}\")\n",
    "        \n",
    "        print(\"\\n--- Resumos dos Chunks ---\")\n",
    "        for i, summary in enumerate(results['chunk_summaries'], 1):\n",
    "            print(f\"\\nChunk {i}:\\n{summary}\\n{'='*50}\")\n",
    "            \n",
    "        print(\"\\n--- Resumo Final ---\")\n",
    "        print(results['final_summary'])\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro fatal: {str(e)}\")\n",
    "        print(\"Ocorreu um erro durante a execução do programa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Avaliação de Resumos de LLMs\n",
    "\n",
    "Utilize as métricas BLEU e ROUGE para comparar os resultados dos prompts do exercício 8 com o seu resumo, feito no exercício 7 (utilize qualquer LLM para traduzir entre inglês e portugês se necessário). Aplique as métricas, tanto ao resumo final, quanto ao resumo de cada chunk. Interprete as métricas considerando que o seu resumo é o gabarito. Os resumos (final e de cada chunk) convergem? Quais informações foram omitidas entre os dois resumos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n",
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacrebleu in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: rouge-score in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: portalocker in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from sacrebleu) (3.0.0)\n",
      "Requirement already satisfied: regex in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from sacrebleu) (2024.11.6)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from sacrebleu) (2.1.3)\n",
      "Requirement already satisfied: colorama in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: absl-py in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: tqdm in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\infnet_ultimo_semestre\\tp3_eng_de_prompt_parte_2_local\\venv\\lib\\site-packages (from portalocker->sacrebleu) (308)\n",
      "\n",
      "--- Métricas do Resumo Final ---\n",
      "BLEU (Effective Order): 0.4313\n",
      "ROUGE-1: 0.7111\n",
      "ROUGE-2: 0.4651\n",
      "ROUGE-L: 0.6667\n",
      "\n",
      "--- Métricas do Chunk 1 ---\n",
      "BLEU (Effective Order): 0.0205\n",
      "ROUGE-1: 0.1290\n",
      "ROUGE-2: 0.0690\n",
      "ROUGE-L: 0.1290\n",
      "\n",
      "--- Métricas do Chunk 2 ---\n",
      "BLEU (Effective Order): 0.0205\n",
      "ROUGE-1: 0.1290\n",
      "ROUGE-2: 0.0690\n",
      "ROUGE-L: 0.1290\n",
      "\n",
      "--- Métricas do Chunk 3 ---\n",
      "BLEU (Effective Order): 0.0205\n",
      "ROUGE-1: 0.1290\n",
      "ROUGE-2: 0.0690\n",
      "ROUGE-L: 0.1290\n",
      "\n",
      "--- Médias das Métricas dos Chunks ---\n",
      "BLEU (Effective Order): 0.0205\n",
      "ROUGE-1: 0.1290\n",
      "ROUGE-2: 0.0690\n",
      "ROUGE-L: 0.1290\n"
     ]
    }
   ],
   "source": [
    "# Instalar bibliotecas necessárias\n",
    "!pip install sacrebleu rouge-score nltk\n",
    "\n",
    "# Importações\n",
    "import nltk\n",
    "from sacrebleu.metrics import BLEU\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Baixar recursos do NLTK\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Definindo as variáveis necessárias\n",
    "resumo_gabarito = \"\"\"Este é o texto de referência (gabarito) que será usado para comparação.\n",
    "Você deve substituir este texto pelo seu texto de referência real.\"\"\"\n",
    "\n",
    "resumo_final = \"\"\"Este é o texto candidato que será comparado com o gabarito.\n",
    "Você deve substituir este texto pelo seu texto candidato real.\"\"\"\n",
    "\n",
    "# Lista de resumos de chunks (se necessário)\n",
    "resumos_chunks = [\n",
    "    \"Este é o primeiro chunk do resumo.\",\n",
    "    \"Este é o segundo chunk do resumo.\",\n",
    "    \"Este é o terceiro chunk do resumo.\"\n",
    "]\n",
    "\n",
    "def calcular_metricas(referencia, candidato):\n",
    "    \"\"\"Calcula as métricas BLEU e ROUGE entre referência e candidato\"\"\"\n",
    "    bleu = BLEU(effective_order=True)\n",
    "    rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    bleu_score = bleu.sentence_score(\n",
    "        hypothesis=candidato,\n",
    "        references=[referencia]\n",
    "    ).score / 100\n",
    "    \n",
    "    rouge_scores = rouge.score(referencia, candidato)\n",
    "    \n",
    "    return {\n",
    "        'BLEU (Effective Order)': bleu_score,\n",
    "        'ROUGE-1': rouge_scores['rouge1'].fmeasure,\n",
    "        'ROUGE-2': rouge_scores['rouge2'].fmeasure,\n",
    "        'ROUGE-L': rouge_scores['rougeL'].fmeasure\n",
    "    }\n",
    "\n",
    "def imprimir_metricas(metricas, titulo):\n",
    "    \"\"\"Imprime as métricas formatadas\"\"\"\n",
    "    print(f\"\\n--- {titulo} ---\")\n",
    "    for metrica, valor in metricas.items():\n",
    "        print(f\"{metrica}: {valor:.4f}\")\n",
    "\n",
    "# Calcular métricas para o resumo final\n",
    "metricas_final = calcular_metricas(resumo_gabarito, resumo_final)\n",
    "\n",
    "# Calcular métricas para cada chunk\n",
    "metricas_chunks = []\n",
    "for chunk in resumos_chunks:\n",
    "    metricas_chunk = calcular_metricas(resumo_gabarito, chunk)\n",
    "    metricas_chunks.append(metricas_chunk)\n",
    "\n",
    "# Imprimir métricas do resumo final\n",
    "imprimir_metricas(metricas_final, \"Métricas do Resumo Final\")\n",
    "\n",
    "# Imprimir métricas de cada chunk\n",
    "for i, metricas in enumerate(metricas_chunks, 1):\n",
    "    imprimir_metricas(metricas, f\"Métricas do Chunk {i}\")\n",
    "\n",
    "# Calcular e imprimir médias das métricas dos chunks\n",
    "metricas_medias = {}\n",
    "for metrica in metricas_chunks[0].keys():\n",
    "    valores = [chunk[metrica] for chunk in metricas_chunks]\n",
    "    metricas_medias[metrica] = sum(valores) / len(valores)\n",
    "\n",
    "print(\"\\n--- Médias das Métricas dos Chunks ---\")\n",
    "for metrica, valor in metricas_medias.items():\n",
    "    print(f\"{metrica}: {valor:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão:** O resumo final apresenta métricas superiores às médias dos chunks, especialmente no BLEU e ROUGE-1, mostrando que a combinação dos chunks foi eficaz para criar um resumo mais abrangente e coerente. Os chunks individuais, enquanto úteis, mostram uma queda progressiva de qualidade em termos de cobertura e fidelidade ao conteúdo, especialmente no Chunk 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 Chain of Thoughts para Codificação\n",
    "Exporte o resultado da análise de sentimento do exercício 6 para um arquivo CSV. Agora, construa uma série de prompts com a técnica chain of thoughts para construir uma aplicação streamlit que faça a leitura do resultado da análise de sentimento e faça um gráfico de pizza mostrando a proporção de falas de categoria do episódio. Divida o problema em três prompts e execute o código final. O LLM foi capaz de implementar a aplicação? Qual foi o objetivo de cada prompt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Resumo do Exercício**\n",
    "\n",
    "\n",
    "Este exercício foi realizado em outro arquivo: 10_app_google.py.\n",
    "\n",
    "A técnica utilizada foi Chain of Thoughs (CoT), uma abordagem sequencial que organiza o fluxo em etapas lógicas, desde a validação até a análise e visualização de dados.\n",
    "\n",
    "Prompts e Motivos\n",
    "\n",
    "**Resumo Estatístico**\n",
    "Motivo: Obter uma visão inicial dos dados do CSV, incluindo total de registros, distribuição percentual e variações.\n",
    "\n",
    "**Insights Contextuais** \n",
    "Motivo: Analisar padrões e influências nos dados, fornecendo recomendações baseadas no contexto.\n",
    "Resultado\n",
    "\n",
    "**Plotagem de Gráfico**\n",
    "Com o objetivo de plotar um gráfico de pizza com base nos dados carregados.\n",
    "\n",
    "Os prompts geraram respostas positivas para análise de dados, mas a plotagem do gráfico falhou no ambiente de execução."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
